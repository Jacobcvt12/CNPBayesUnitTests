#+TITLE: Chib's estimation of the marginal density for a hierarchical finite normal mixture
#+DATE:  2015-07-17 Fri
#+email: rscharpf@jhu.edu
#+author:  Rob Scharpf

* Packages

#+begin_src R :tangle scripts/marginal_lik.R
library(RUnit)
##library(CNPBayes)
library(MASS)
library(devtools)
load_all("~/Software/CNPBayes")
#+end_src 

* Galaxies data

#+begin_src R :tangle scripts/marginal_lik.R
data(galaxies)
#+end_src 

Correct the 78th observation:

#+BEGIN_SRC R :tangle scripts/marginal_lik.R
  galaxies[78] <- 26960
#+END_SRC


  
* Fit mixture model

Start by fitting the 3 component mixture model

#+begin_src R :tangle scripts/marginal_lik.R
  mp <- McmcParams(thin=100, iter=1000, burnin=10000, nStarts=20)
  hypp <- Hyperparameters(type="marginal", k=3)
  model <- MarginalModel(data=galaxies/1000, k=3,
                         hypp=hypp,
                         mcmc.params=mp)
  fit <- posteriorSimulation(model)
  dm <- plot(fit, ylim=c(0, 0.4), breaks=50)
  plot.ts(logPrior(chains(fit)))
#+end_src

The plot suggests 4 components may be a better fit.

#+BEGIN_SRC R 
  fit4 <- posteriorSimulation(model, k=4)
  dm4 <- plot(fit4, ylim=c(0, 0.4), breaks=50)
#+END_SRC

* Computing the marginal likelihood
** COMMENT Using CNPBayes function

Compute the marginal likelihood for the K=3 model and compare to the
published marginal likellihood for the 3-cluster model with unequal
variance:

#+BEGIN_SRC R :tangle scripts/marginal_lik.R
  published.mlik <- -226.791
  x <- computeMarginalLik(list(fit))$marginal
  mlik <- x[[1]]["marginal"]
  print(mlik)
  tryCatch(checkEquals(as.numeric(mlik), published.mlik, tolerance=3),
           error=function(e) "CNPBayes estimate not within tolerance")
#+END_SRC


The target posterior distribution is given by

$$ p(\psi | y ) = \frac{p(y | \psi) p(\psi)}{m(y)},$$ where the
marginal likelihood is given by $m(y)$.  We can rewrite this
expression in terms of the marginal density for $y$ as

$$ log[m(y)] = log[p(y|\psi^*)] + log[p(\psi^*)] - log[p(\psi^* |
y)]$$

for any ordinate $\psi^*$.  The first 2 terms on the RHS, the data log
liklelihood and the prior, are known and we compute these in the
following section.  In all that follows, we assume that the chain has
reached stationarity.  Convergence should be confirmed prior to
estimating the marginal likelihood.

** The data log likelihood and the log prior

The log likelihood and log prior are straightforward to compute and we
evaluate each at the modal ordinates, $\psi^*$.  There are several
ways to extract modal ordinates.

#+BEGIN_SRC R :tangle scripts/marginal_lik.R
  modal.ordinates <- modes(fit)
  print(modal.ordinates)
  ## Update slots of the paramters in MarginalModel with the modal.ordinates
  fit2 <- useModes(fit)
  identical(theta(fit2), modal.ordinates[["theta"]])
  identical(sigma2(fit2), modal.ordinates[["sigma2"]])
  ## Find the modal.ordinate using argMax, which looks at log lik *
  ## prior for each MCMC iteration
  i <- argMax(fit)
  thetas <- theta(chains(fit))[i, ]
  identical(thetas, modal.ordinates[["theta"]])
#+END_SRC

*** Complete data log likelihood and log prior

The complete data log likelihood and log prior at the modal ordinates
are given by 

#+BEGIN_SRC R :tangle scripts/marginal_lik.R
  loglik <- modes(fit)[["loglik"]]
  fit2 <- useModes(fit)
  s2.loglik <- .Call("stageTwoLogLik", fit2)
  logprior <- modes(fit)[["logprior"]]
#+END_SRC


Alternatively, the data log likelihood calculation is implemented in
  C++ and could be computed directly for the model at the modal
  ordinates:

#+BEGIN_SRC R :tangle scripts/marginal_lik.R
  (loglikC <- .Call("loglik", fit2))
  stage2.loglik <- .Call("stageTwoLogLik", fit2)
  loglikC <- loglikC + stage2.loglik
#+END_SRC

The joint prior is $p(\sigma^2_0, \nu_0, \mu, \tau^2, \pi)$ and is
factored as $p(\sigma^2_0)p(\nu_0)p(\mu)p(\tau^2)p(\pi)$.

#+BEGIN_SRC R :tangle scripts/marginal_lik.R
  hypp <- hyperParams(fit2)
  eta.0 <- CNPBayes:::eta.0(hypp)
  m2.0 <- CNPBayes:::m2.0(hypp)
  lpriorR <- log(dgeom(nu.0(fit2), CNPBayes:::betas(hypp))) +
      log(dgamma(CNPBayes:::sigma2.0(fit2), CNPBayes:::a(hypp), CNPBayes:::b(hypp))) +
          log(dnorm(mu(fit2), CNPBayes:::mu.0(hypp), sqrt(CNPBayes:::tau2.0(hypp)))) +
              log(dgamma(1/tau2(fit2), 1/2*eta.0, 1/2*eta.0*m2.0)) +
                  log(gtools::ddirichlet(p(fit2), CNPBayes:::alpha(hypp)))
  lpriorC <- .Call("compute_logprior", fit2)
  checkIdentical(lpriorR, lpriorC)
#+END_SRC

The likelihood of the population-level parameters at the second stage
of the model is given by $p(\theta | \mu, \tau) p(\sigma^2 | \nu_0,
\sigma_0^2)$. We compute this in R

#+name: stage2_loglik
#+BEGIN_SRC R :tangle scripts/marginal_lik.R
  n0 <- CNPBayes:::nu.0(fit2)
  sigma2.0 <- CNPBayes:::sigma2.0(fit2)
  stage2.loglik <- sum(log(dnorm(theta(fit2), mu(fit2), tau(fit2)) *
                               dgamma(1/sigma2(fit2), 1/2*n0, 1/2*n0*sigma2.0)))
  loglikAndPrior <- loglik + logprior
#+END_SRC

** Estimation of p(\psi^* | y)


The difference in the first two terms of the expression for the
marginal density (that includes the second stage likelihood) and the
tabled value for the true log marginal density should correspond to
the true posterior probability at the modal ordinates $\psi^*$.

#+BEGIN_SRC R :tangle scripts/marginal_lik.R
  true.posterior <- loglikAndPrior - published.mlik  
#+END_SRC


*** Block updates

The objective is to estimate $p(\theta^*, \sigma^{2*}, \pi^*, \mu^*, \tau^*, \nu_0^*, \sigma_0^{2*} | y)$,
which can be expressed as

$$  p(\theta^* | y ) p(\sigma^{2*} | y, \theta^*) p(\pi^* | y, \theta^*, \sigma^{2*}) p(\mu^* | y, \theta^*, \sigma^{2*}, \pi^*)p(\tau^*| \theta^*, \sigma^{2*}, \pi^*, \mu^*) 
p(\tau^*| \theta^*, \sigma^{2*}, \pi^*, \mu^*, \tau^*) p(\nu_0^*| \theta^*, \sigma^{2*}, \pi^*, \mu^*, \tau^*)p(\sigma_0^{2*}| \theta^*, \sigma^{2*}, \pi^*, \mu^*, \tau^*, \nu_0^*)
$$

The first term is

$$ p(\theta^* | y ) = \int p(\theta^* | y, \sigma^2, \pi, z, \ldots) p(\sigma^2, \pi, z | y, \ldots)d(\sigma^2, \mu, \pi, z, \dots)$$

**** Estimation of p(\theta^* | y)

An estimate for the first term is obtained by taking an ergodic average of

$$p(\theta^* | y, \sigma^{2(s)}, z^{(s)}),$$

using the posterior draws of (\sigma^2, \pi, z). No additional MCMC is
required for this estimate.  It does not matter whether we pass the
object ~fit2~ or ~fit~ because the chains in these 2 objects are
identical. 

#+BEGIN_SRC R :tangle scripts/marginal_lik.R
  ptheta.star <- .Call("marginal_theta", fit2)
  (p.theta.rb <- log(mean(ptheta.star)))
#+END_SRC

**** Estimation of $p(\sigma^{2*} | y, \theta^*)$

Note

$$p(\sigma^{2*} | y, \theta^*)  = \int p(\sigma^{2*} | y, \theta^*, \pi, z) p(\pi, z | y, \theta^*)d\pi dz.$$ 

To estimate $p(\sigma^{2*} | y)$, we take an ergodic average of
$p(\sigma^{2*} | y, \pi^{(s)}, z^{(s)})$ using draws of (\pi, z) from
a **reduced** Gibb's sampler. ** It is important to have draws of $z$
from [z | y, \theta*] (not [z | y]) and draws of $\pi$ from [\pi | y,
\theta*].

We allow the user to run fewer MCMC iterations in the reduced Gibbs by
 specifying an integer value for the argument $T2$ of the
 ~computeMarginalLik~ function.  The C++ function for the reduced
 Gibb's is called below.

**Refactoring needed:** 

- /This function is poorly named. Not sure why 'permutedz' is in the
  name/.

- Much of the code in ~.pthetastar~ is for permuting the modes.  This
  should be removed from estimation of the marginal density.  In
  particular, we should calculate the marginal density for whatever
  ordering of modes is passed in the MarginalModel object.  Permuting
  to a different set of modes would be a method defined for marginal
  model that is irrelevant for the computation of Gibb's.

- Check whether any of the methods for running the reduced Gibb's are
  outdated and can be removed

#+BEGIN_SRC R :tangle scripts/marginal_lik.R
  T <- 500
  mp.reduced <- McmcParams(iter=T, thin=2, burnin=0)
  fit.psigma2 <- fit
  mcmcParams(fit.psigma2, force=TRUE) <- mp.reduced
  ## I do not recall why z is not updated.
  ##fit.psigma2 <- .Call("permutedz_reduced1", object)
  fit.psigma2 <- .Call("reduced_sigma", fit.psigma2)
  p.sigma2 <- .Call("p_sigma_reduced", fit.psigma2)
  p.sigma.rb <- log(mean(p.sigma2))
#+END_SRC

***** COMMENT Debugging small values in p(sigma^* | ...)
#+BEGIN_SRC R
  plot(fit.psigma2, breaks=50, ylim=c(0, 0.4))
  plot.ts(sigma2.0(chains(fit.psigma2)))

  checkIdentical(theta(fit.psigma2), modes(fit)[["theta"]])
  identical(modes(fit.psigma2), modes(fit))
  psigma.star <- .Call("p_sigma_reduced", fit.psigma2)
  (p.sigma.rb <- log(mean(psigma.star)))


  sigma2star <- modes(fit)[["sigma2"]]
  thetastar <- modes(fit)[["theta"]]
  prec <- 1/sigma2star
  Z <- z(chains(fit.psigma2))
  K <- 3
  s20chain <- sigma2.0(chains(fit.psigma2))
  nu0chain <- nu.0(chains(fit.psigma2))
  x <- y(fit.psigma2)



  ## the density estimates for the component variances gets very small
  ## because sigma2.0 gets very small.  sigma2.0 should not get very
  ## small as a result of fixing theta.
  S <- iter(fit.psigma2)
  p_prec <- rep(NA, S)
  for(s in 1:S){
    ##for(int s=0; s < S; ++s){
    zz = Z[s, ]
    nn = tableZ(K, zz) ;
    s20 = s20chain[s] ;
    nu0 = nu0chain[s] ;

    ss <- rep(NA, K)
    for(k in 1:K){
      ss[k] <- sum((x[zz==k] - thetastar[k])^2)
    }
    total <- 1
    nu.n <- nu0 + nn
    sigma2.n = 1/nu.n*(nu0*s20 + ss) ;
    d <- rep(NA, K)
    for(k in 1:K){
      d[k] <- dgamma(prec[k], 0.5*nu.n[k], 0.5*nu.n[k]*sigma2.n[k])
    }
    p_prec[s] <- prod(d)
  }
#+END_SRC

**** Estimation of $p(\pi^* | y, \theta^*, \sigma^{2*})$  

We write the third term as

$$p(\pi^{*} | y, \theta^*, \sigma^{2*})  = \int p(\pi^* | y, \theta^*, \sigma^{2*}, z) p(z | y, \theta^*, \sigma^{2*})dz.$$ 

To estimate $p(\pi^{*} | y)$, we take an ergodic average of
$p(\pi^{*} | y, \theta^*, \sigma^{2*}, z^{(s)})$ using draws of $z
from a **reduced** Gibb's sampler. The draws of $z$ are from [z | y,
\theta^*, \sigma^{2*}]. The C function for simulating from [z|theta^*,
\sigma^{2*}] is implemented in C+++.

// It appears that in the current implementation, a reduced Gibb's
with $\theta$ and $\sigma^2$ fixed was not run./

#+BEGIN_SRC R :tangle scripts/marginal_lik.R
  fit.pi.star <- fit
  mcmcParams(fit.pi.star, force=TRUE) <- mp.reduced
  fit.pi.star <- .Call("reduced_pi", fit.pi.star)
  identical(modes(fit.pi.star), modes(fit))
  p.pi.star <- .Call("p_pmix_reduced", fit.pi.star)
  (p.pi.rb <- log(mean(p.pi.star)))
  ## check
  zz <- z(chains(fit.pi.star))
  gtools::ddirichlet(modes(fit)[["mixprob"]], alpha(hypp) + table(zz[2,]))
  mp <- modes(fit)[["mixprob"]]
  ztab <- tableZ(3, z(fit))
  ##ddirichlet(mp, 1+ztab)
#+END_SRC

** COMMENT Computing the marginal density

Since ~p.theta.rb~, ~p.sigma2.rb~, and ~p.pi.rb~ are already on the
log scale, the Chib's estimate of the marginal density (log-scale) is
given by

#+BEGIN_SRC R :tangle scripts/marginal_lik.R
  m.y <- loglikAndPrior - (p.theta.rb + p.sigma.rb + p.pi.rb)
#+END_SRC

Bias correction and comparison to published value:

#+BEGIN_SRC R :tangle scripts/marginal_lik.R
  m.bc <- m.y + log(factorial(3))
  m.bc - published.mlik
#+END_SRC

** Extension of block updates to second stage model parameters \mu, \tau^2, \nu_0, and \sigma_0^2.

*** Estimation of p(\mu | y, \theta^*, \sigma^{2*}, \pi^*)

We have

$$p(\mu^* | y, \theta^*, \sigma^{2*}, \pi^*) = \int p(\mu^{*} | y, \theta^*, \sigma^{2*}, \pi^*, \tau^{2}, \nu_0, \sigma_0^2, z)   p(\tau^{2}, \nu_0, \sigma_0^2, z | y, \theta^*, \sigma^{2*}\pi^*)d\tau^2d \nu_0 d \sigma_0^2 dz.$$ 

To estimate $p(\mu^{*} | y, y, \theta^, \sigma^{2*}, \pi^*)$, we take
an ergodic average of $p(\pi^{*} | y, \theta^*, \sigma^{2*},
\tau^{2(s)}, \nu_0^{(s)}, \sigma_0^{2(s)}, z^{(s)})$ using draws of
$z$ from a **reduced** Gibb's sampler. The draws of $z$ are from [z |
y, \theta^*, \sigma^{2*}, \pi^*]. The function for simulating is
implemented in C++.

#+BEGIN_SRC R :tangle scripts/marginal_lik.R
  fit.mustar <- fit
  mcmcParams(fit.mustar, force=TRUE) <- mp.reduced
  fit.mustar <- .Call("reduced_mu", fit.mustar)
  identical(modes(fit.mustar), modes(fit))
  ##tau2s <- tau2(chains(fit.mustar))
  p.mustar <- .Call("p_mu_reduced", fit.mustar)
  (p.mu.rb <- log(mean(p.mustar)))
#+END_SRC

*** COMMENT Debugging p(\mu^*| \ldots)

Values of $p(\mu^* |\ldots)$ are near 0, but this seems strange if
$\mu^*$ is a modal ordinate and $p(\mu^*| ldots)$ is the full
conditional (with constraints).
 
#+BEGIN_SRC R
  fit.mustar <- fit
  mcmcParams(fit.mustar, force=TRUE) <- mp.reduced
  fit.mustar <- .Call("reduced_mu", fit.mustar)
  identical(modes(fit.mustar), modes(fit))
  ##tau2s <- tau2(chains(fit.mustar))
  p.mustar <- .Call("p_mu_reduced", fit.mustar)

  median(mu(chains(fit.mustar))) ## mean of chain is strange...
  plot.ts(mu(chains(fit.mustar)))
  plot.ts(tau(chains(fit.mustar)))
  median(tau2(chains(fit.mustar))) ## tau2 is very large
  table(z(chains(fit.mustar))[1, ])
  table(z(chains(fit.mustar))[50, ])
  table(z(chains(fit.mustar))[200, ])
  plot.ts(nu.0(chains(fit.mustar))) ## tau2 is very large
  plot.ts(sigma2.0(chains(fit.mustar))) ## tau2 is very large


  mu <- modes(fit.mustar)[["mu"]]


  total <- length(y(fit.mustar))
  ##  for(int s = 0; s < S; ++s){
  ##    zz = Z(s, _) ;
  zz <- z(chains(fit.mustar))[argMax(fit.mustar), ]
  nn <- table(zz)
  thetastar <- modes(fit.mustar)[["theta"]]
  thetabar <- sum(nn * thetastar / total)
  hypp <- hyperParams(fit.mustar)
  mu0 <- mu.0(hypp)
  tau20 <- tau2.0(hypp)
  tau20.tilde <- 1/tau20
  tau2.tilde <- 1/tau2(fit)
  K <- 3
  postprec <- tau20.tilde + K*tau2.tilde
  w1 <- tau20.tilde/postprec
  w2 <- K*tau2.tilde/postprec
  mu.k =  w1*mu0 +  w2*thetabar ;
  tau.k = sqrt(1.0/postprec) ;
  dnorm(mu, mu.k, tau.k)

  hypp <- hyperParams(fit.mustar)
  mu0 <- mu.0(hypp)
  tau20 <- tau2.0(hypp)
  tau20.tilde <- 1/tau20
  tau2chain <- tau2(chains(fit.mustar))
  tau2.tilde <- 1/tau2chain
  Z <- z(chains(fit.mustar))
  K <- 3
  thetastar <- modes(fit.mustar)[["theta"]]
  S <- iter(fit.mustar)
  p.mu <- rep(NA, S)
  mustar <- modes(fit.mustar)[["mu"]]

  for(s in 1:iter(fit.mustar)){
    zz = Z[s, ] ;
    nn = tableZ(K, zz) ;
    total <- sum(nn)
    thetabar <- sum(nn*thetastar/total)
    post.prec <- tau20.tilde + K * tau2.tilde[s]
    ##double post_prec = tau20_tilde + K*tau2_tilde[s] ;
    w1 = tau20.tilde/post.prec ;
    w2 = K*tau2.tilde[s]/post.prec ;
    mu.k =  w1*mu0 +  w2*thetabar ;
    tau.k = sqrt(1/post.prec) ;
    p.mu[s]  = dnorm(mustar, mu.k, tau.k) ;
  }
#+END_SRC

*** Estimation of p(\tau2 | y, \theta^*, \sigma^{2*}, \pi^*, \mu^*)

#+BEGIN_SRC R :tangle scripts/marginal_lik.R
  fit.taustar <- fit
  mcmcParams(fit.taustar, force=TRUE) <- mp.reduced
  fit.taustar <- .Call("reduced_tau", fit.taustar)
  identical(modes(fit.taustar), modes(fit))
  p.taustar <- .Call("p_tau_reduced", fit.mustar)
  ##
  ## There is only 1 value for p.taustar -- we did not need a chain.
  ## 'reduced_tau' may be unnecessary
  ##
  (p.tau.rb <- log(p.taustar))
#+END_SRC

**** COMMENT Verify p(\tau^2| ...)

#+BEGIN_SRC R
  tau2star <- modes(fit)[["tau2"]]
  mustar <- modes(fit)[["mu"]]
  K <- 3
  eta0 <- eta.0(hypp)
  etak <- eta0+K
  m20 <- m2.0(hypp)

  s2.k <- sum((thetastar - mustar)^2)
  m2.k <- 1/etak * (eta0 * m20 + s2.k)
  p.tau <- dgamma(1/tau2star, 1/2*etak, 1/2*etak*m2.k)
#+END_SRC

#+BEGIN_SRC R 
  (m.y <- loglikAndPrior - (p.theta.rb + p.sigma.rb + p.pi.rb + p.mu.rb + p.tau.rb))
#+END_SRC

*** Estimation of p(\nu_0^* | y, \theta^*, \sigma^{2*}, \pi^*, \tau^{2*})

 $\nu_0$ does not have a conjugate prior -- we sample from an
 un-normalized probability distribution.  As $\nu_0$ is restricted to
 an integer value, we simply compute the un-normalized probabilities
 for integers 1, \ldots, 100 and scale the un-normalized probability
 at $\nu_0^*$ by the total of the un-normalized probabilities.

#+BEGIN_SRC R :tangle scripts/marginal_lik.R
  fit.nu0star <- fit
  mcmcParams(fit.nu0star, force=TRUE) <- mp.reduced
  fit.nu0star <- .Call("reduced_nu0", fit.nu0star)
  identical(modes(fit.nu0star), modes(fit))
  p.nu0star <- .Call("p_nu0_reduced", fit.nu0star)
  (p.nu0.rb <- log(mean(p.nu0star)))
#+END_SRC

#+BEGIN_SRC R
  p.star = p.theta.rb + p.sigma.rb + p.pi.rb + p.mu.rb + p.tau.rb + p.nu0.rb
  (m.y <- loglikAndPrior - p.star)
#+END_SRC

*** Estimation of p(\sigma2_0^* | y, \theta^*, \sigma^{2*}, \pi^*, \tau^{2*}, \nu_0^*)

#+BEGIN_SRC R :tangle scripts/marginal_lik.R
  fit.s20star <- fit
  mcmcParams(fit.s20star, force=TRUE) <- mp.reduced
  fit.s20star <- .Call("reduced_s20", fit.s20star)
  p.s20star <- .Call("p_s20_reduced", fit.s20star)
  p.s20.rb <- log(p.s20star)
#+END_SRC

#+BEGIN_SRC R
  p.star = p.theta.rb + p.sigma.rb + p.pi.rb + p.mu.rb + p.tau.rb + p.nu0.rb + p.s20.rb
  (m.y <- loglikAndPrior - p.star)
  m.bc <- m.y - log(factorial(3))
  published.mlik - m.bc
#+END_SRC

* R wrapper for marginal likelihood

#+BEGIN_SRC R
  pstar <- matrix(NA, 7, 4)
  tmp <- blockUpdates(fit, McmcParams(iter=1))
  rownames(pstar) <- names(tmp)
  pstar[, 1] <- blockUpdates(fit, McmcParams(iter=500))
  pstar[, 2] <- blockUpdates(fit, McmcParams(iter=1000))
  pstar[, 3] <- blockUpdates(fit, McmcParams(iter=5000))
  pstar[, 4] <- blockUpdates(fit, McmcParams(iter=10000))
  round(pstar, 3)
  all(matrixStats::rowSds(pstar) < 0.1)
  m.y <- marginalLikelihood(fit, 1000)
#+END_SRC


* Speed improvement

- do not store the chains in the reduced Gibb's
- do not permute the z-labels.  If we do, do it outside the
  computation of the marginal density.  Only reasonable time to do
  this is if there is not a clear winner.











